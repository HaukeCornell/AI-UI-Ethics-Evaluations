# Interface Examples and Data Visualization Plan

## Overview

Participants will be shown interface mockups accompanied by user evaluation data presented as gauge visualizations. The data presentation varies by experimental condition, with all participants seeing the same interfaces but different metric presentations.

---

## Data Visualization Format

### Gauge Chart Presentation
User evaluation data will be presented using gauge charts (speedometer-style visualizations) commonly used in business dashboards. Each gauge shows:
- Scale from -3 to +3 (following UEQ methodology)
- Color coding: Red (negative), Yellow (neutral), Green (positive)
- Needle indicating average user rating
- Clear labels for each metric

### Condition A: Standard UX Metrics
Participants see 4-6 standard UX evaluation gauges:
- **Efficiency**: "efficient/inefficient"
- **Satisfaction**: "satisfying/frustrating" 
- **Ease of Use**: "easy/complicated"
- **Clarity**: "clear/confusing"
- **Overall Experience**: "good/bad"

### Condition B: Enhanced Ethics Metrics
Participants see the same standard metrics PLUS additional ethical evaluation gauges:
- **Manipulation**: "manipulative/respectful"
- **Deception**: "deceptive/honest"
- **Pressure**: "pressuring/suggesting"
- **Addiction Risk**: "addictive/healthy"
- **Transparency**: "transparent/hidden"

---

## Interface Categories

### Category 1: Dark Pattern Examples (4-5 interfaces)
Examples based on documented manipulative design practices:

**Example A: Subscription Dark Patterns**
- Interface showing confusing cancellation flow
- Hidden fees, unclear billing terms
- Difficult-to-find cancel options
- Expected metrics: Low on ethics scales, mixed on usability

**Example B: Social Media Engagement Manipulation**
- Infinite scroll with intermittent reinforcement
- Fear-of-missing-out messaging
- Excessive notifications and badges
- Expected metrics: High addiction potential, moderate usability

**Example C: E-commerce Pressure Tactics**
- Fake scarcity warnings ("Only 2 left!")
- Hidden costs until final checkout
- Pre-checked add-ons and upsells
- Expected metrics: High pressure/manipulation, decent efficiency

### Category 2: Ethical/Neutral Examples (4-5 interfaces)
Well-designed interfaces following ethical practices:

**Example A: Transparent Privacy Settings**
- Clear opt-in/opt-out controls
- Plain language explanations
- Easy access to privacy options
- Expected metrics: High on ethics scales, good usability

**Example B: Accessible E-commerce Checkout**
- Clear pricing throughout process
- No hidden fees or charges
- Multiple payment options clearly presented
- Expected metrics: High transparency, excellent usability

**Example C: Mindful Social Media Features**
- Usage time tracking and limits
- Clear notification controls
- "Take a break" suggestions
- Expected metrics: Low addiction risk, good user experience

### Category 3: Ambiguous/Mixed Examples (3-4 interfaces)
Designs with both positive and potentially concerning elements:

**Example A: Gamified Fitness App**
- Achievement badges and streaks
- Social comparison features
- Push for daily engagement
- Expected metrics: Moderate addiction concern, high engagement

**Example B: Personalized News Feed**
- Algorithm-driven content selection
- Engagement optimization
- Filter bubble potential
- Expected metrics: Mixed ethics scores, high efficiency

### Category 4: AI-Generated Examples (2-3 interfaces)
*[If included - clearly labeled as AI-generated]*
- Interfaces created using AI design tools
- Accompanied by AI-generated user evaluation data
- Used to test responses to novel design patterns

---

## Data Sources

### Real User Data
Primary source: User evaluation data from previous published research on dark patterns and UX metrics, including:
- Data from the attached DIS paper research
- Published UEQ evaluation datasets
- Publicly available UX research findings

### Synthesized Data
When real data is unavailable for specific interfaces:
- Data points extrapolated from similar interface evaluations
- Validated against known patterns in UX research
- Clearly documented as synthesized rather than directly collected

### AI-Generated Data
*[If included]*
- Evaluation data generated using large language models
- Based on established UX evaluation frameworks
- Clearly labeled as AI-generated to participants
- Used to explore responses to novel scenarios

---

## Presentation Format

### Interface Display
- High-fidelity mockups presented at consistent size
- Clean, professional presentation without distracting elements
- Focus on key interaction elements relevant to evaluation

### Gauge Layout
- Consistent placement below each interface
- Clear labeling and legend
- Responsive design for different screen sizes
- Professional appearance matching business dashboard standards

### Additional Context
When necessary for comprehension:
- Brief, neutral description of interface purpose
- Context about user task or scenario
- No leading language that might bias evaluation

---

## Ethical Considerations

### Transparency
- All data sources clearly documented
- AI-generated content explicitly labeled
- Participants informed about data presentation variations in debrief

### Participant Wellbeing
- Content warnings for potentially manipulative interface examples
- Option to skip any interface that causes discomfort
- Clear indication that examples may represent problematic design practices

### Research Validity
- Balanced representation across interface categories
- Consistent data presentation methodology
- Pilot testing to ensure clear interpretation of gauge visualizations