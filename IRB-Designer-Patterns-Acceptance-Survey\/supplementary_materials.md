# Supplementary IRB Materials

## Literature Review Summary and Justification

### Background Research
This study builds on established research demonstrating that:

1. **Dark patterns are prevalent in digital interfaces** (Gray et al., 2018; Mathur et al., 2019)
2. **Standard UX metrics fail to capture manipulative design elements** (as evidenced in the attached DIS paper)
3. **Designers face ethical dilemmas in professional practice** (Wong, 2021; Chamorro et al., 2023)
4. **Business metrics often prioritize engagement over user wellbeing** (Ledger & Bailly, 2011)

### Research Gap
Current literature lacks empirical evidence on whether enhanced UX evaluation metrics can influence real-world design decision-making toward more ethical outcomes. This study addresses this gap by testing whether presenting user evaluation data with ethical dimensions affects professional designers' implementation decisions.

### Theoretical Framework
The study draws on:
- **Value-sensitive design theory** (Friedman, 1996)
- **Behavioral decision-making research** (Kahneman & Tversky, 1979)
- **Professional ethics in design** (Monteiro, 2019)

---

## Detailed Risk Assessment

### Risk Category: Minimal Risk
This study qualifies as minimal risk research under federal guidelines, as risks are no greater than those encountered in daily professional activities.

### Specific Risk Analysis

#### Psychological Discomfort
- **Risk**: Mild discomfort when viewing manipulative interface examples
- **Likelihood**: Low to moderate
- **Mitigation**: 
  - Content warnings provided
  - Option to skip uncomfortable examples
  - Clear framing as research examples, not endorsements
  - Debrief explaining study purpose

#### Professional Reflection
- **Risk**: Participants may question their own professional practices
- **Likelihood**: Low
- **Mitigation**: 
  - Emphasis on learning and improvement
  - No judgment of individual decisions
  - Resources for ethical design practices in debrief

#### Time Burden
- **Risk**: 30-35 minutes of participant time
- **Likelihood**: Certain but acceptable
- **Mitigation**: 
  - Clear time estimate provided upfront
  - Fair compensation ($8-10)
  - Option to withdraw at any time

#### Confidentiality Breach
- **Risk**: Inadvertent disclosure of professional opinions
- **Likelihood**: Very low
- **Mitigation**: 
  - No personally identifiable information collected
  - Secure data storage on Cornell systems
  - Aggregated analysis and reporting only

### Risk-Benefit Analysis
The minimal risks are outweighed by potential benefits to the design profession and society through improved ethical design practices.

---

## Data Management Plan Details

### Data Collection
- **Platform**: Cornell Qualtrics (FISMA compliant)
- **Storage**: Cornell Box (encrypted, access-controlled)
- **Retention**: 3 years post-publication for verification purposes
- **Access**: Principal investigator (Hauke Sandhaus) and faculty advisor (Helen Nissenbaum) only

### Data Security Measures
- **Encryption**: All data encrypted in transit and at rest
- **Access Control**: Multi-factor authentication required
- **Backup**: Automated secure backups to Cornell systems
- **Monitoring**: Regular security audits per Cornell IT policies

### De-identification Protocol
1. No names, email addresses, or direct identifiers collected
2. IP addresses not recorded
3. Demographic data aggregated for analysis
4. Individual responses not traceable to participants
5. Random ID assignment for data organization

---

## Recruitment Strategy Details

### Target Population Justification
Professional designers are the appropriate population because:
- They make real-world decisions about interface implementation
- They have relevant expertise to evaluate design quality
- They face ethical dilemmas in professional practice
- Results can directly inform professional development

### Sample Size Justification
Target of 100-150 participants provides:
- Sufficient power for statistical analysis (Cohen's d = 0.5, α = 0.05, β = 0.80)
- Adequate representation across experience levels and roles
- Buffer for potential incomplete responses
- Ability to detect meaningful differences between conditions

### Recruitment Channels
1. **Professional Networks**: LinkedIn, design communities
2. **Academic Networks**: HCI conferences, university alumni
3. **Online Communities**: Designer forums, social media groups
4. **Snowball Sampling**: Referrals from initial participants
5. **Paid Platforms**: Prolific for supplemental recruitment

---

## Quality Assurance Measures

### Attention Checks
- Embedded questions to verify engagement
- Consistency checks across similar questions
- Minimum time thresholds for each section

### Response Validation
- Required fields for key decisions
- Character limits to encourage thoughtful responses
- Option to flag low-quality responses for exclusion

### Pilot Testing
- Small pilot (n=10-15) before full launch
- Test technical functionality and timing
- Refine question wording based on feedback
- Validate gauge chart interpretation

---

## Potential Limitations and Mitigation

### Limitation: Hypothetical Decisions
- **Issue**: Laboratory decisions may not reflect real-world choices
- **Mitigation**: Use realistic scenarios and professional context framing

### Limitation: Self-Selection Bias
- **Issue**: Ethically-minded designers may be more likely to participate
- **Mitigation**: Recruit through diverse channels, include compensation

### Limitation: Social Desirability
- **Issue**: Participants may provide socially acceptable responses
- **Mitigation**: Emphasize confidentiality, include neutral examples

### Limitation: Cultural Context
- **Issue**: Design ethics may vary across cultures
- **Mitigation**: Focus on widely-accepted ethical principles, note limitations

---

## Debrief and Follow-up Plan

### Immediate Debrief
- Explain study purpose and hypotheses
- Clarify any concerns about interface examples
- Provide resources for ethical design practices
- Offer to answer questions via email (hgs52@cornell.edu or hn288@cornell.edu)

### Results Sharing
- Participants can request summary of findings
- Results will be shared through academic publications
- Practical implications communicated to design community

### Resource Provision
- Links to ethical design guidelines and resources
- Information about professional development opportunities
- Contact information for follow-up questions

---

## Timeline and Milestones

1. **IRB Submission**: [Date]
2. **IRB Review Period**: 2-4 weeks
3. **Pilot Testing**: 1 week post-approval
4. **Recruitment Launch**: 2 weeks post-approval
5. **Data Collection**: 4-6 weeks
6. **Analysis**: 6-8 weeks
7. **Manuscript Preparation**: 8-12 weeks
8. **Results Dissemination**: Conference submission and publication

---

## Compliance Statements

### Human Subjects Training
Principal investigator (Hauke Sandhaus) and faculty advisor (Helen Nissenbaum) have completed current CITI human subjects research training.

### Data Protection Compliance
Study design complies with:
- Cornell University data protection policies
- GDPR requirements for international participants
- Professional ethics guidelines for design research

### Conflict of Interest
No financial conflicts of interest exist. Academic interest in promoting ethical design practices is disclosed.