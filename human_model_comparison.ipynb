{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human vs Model UX Assessment Comparison\n",
    "\n",
    "This notebook compares human evaluations with model evaluations for dark patterns, focusing on UX KPI metrics and pattern assessments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "\n",
    "# Set up visual style\n",
    "plt.style.use('ggplot')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"comparison_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "First, let's load both human evaluations and model evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human data shape: (348, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metadata_participant_id</th>\n",
       "      <th>metadata_timestamp</th>\n",
       "      <th>metadata_pattern_type</th>\n",
       "      <th>metadata_interface_id</th>\n",
       "      <th>score_inefficient_efficient</th>\n",
       "      <th>score_interesting_not_interesting</th>\n",
       "      <th>score_clear_confusing</th>\n",
       "      <th>score_enjoyable_annoying</th>\n",
       "      <th>score_organized_cluttered</th>\n",
       "      <th>score_addictive_non_addictive</th>\n",
       "      <th>score_supportive_obstructive</th>\n",
       "      <th>score_pressuring_suggesting</th>\n",
       "      <th>score_boring_exciting</th>\n",
       "      <th>score_revealed_covert</th>\n",
       "      <th>score_complicated_easy</th>\n",
       "      <th>score_unpredictable_predictable</th>\n",
       "      <th>score_friendly_unfriendly</th>\n",
       "      <th>score_deceptive_benevolent</th>\n",
       "      <th>data_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P002</td>\n",
       "      <td>2025-04-04T10:06:23</td>\n",
       "      <td>Overcomplicated Process</td>\n",
       "      <td>interface_002</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P002</td>\n",
       "      <td>2025-04-04T10:06:25</td>\n",
       "      <td>Sneaking Bad Default</td>\n",
       "      <td>interface_004</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P002</td>\n",
       "      <td>2025-04-04T10:06:29</td>\n",
       "      <td>Toying With Emotion</td>\n",
       "      <td>interface_008</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P002</td>\n",
       "      <td>2025-04-04T10:06:35</td>\n",
       "      <td>Endlessness</td>\n",
       "      <td>interface_014</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P003</td>\n",
       "      <td>2025-04-04T10:06:26</td>\n",
       "      <td>Expectation Result Mismatch</td>\n",
       "      <td>interface_005</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metadata_participant_id   metadata_timestamp        metadata_pattern_type  \\\n",
       "0                    P002  2025-04-04T10:06:23      Overcomplicated Process   \n",
       "1                    P002  2025-04-04T10:06:25         Sneaking Bad Default   \n",
       "2                    P002  2025-04-04T10:06:29          Toying With Emotion   \n",
       "3                    P002  2025-04-04T10:06:35                  Endlessness   \n",
       "4                    P003  2025-04-04T10:06:26  Expectation Result Mismatch   \n",
       "\n",
       "  metadata_interface_id  score_inefficient_efficient  \\\n",
       "0         interface_002                            6   \n",
       "1         interface_004                            3   \n",
       "2         interface_008                            2   \n",
       "3         interface_014                            5   \n",
       "4         interface_005                            4   \n",
       "\n",
       "   score_interesting_not_interesting  score_clear_confusing  \\\n",
       "0                                  5                      3   \n",
       "1                                  4                      4   \n",
       "2                                  6                      7   \n",
       "3                                  2                      5   \n",
       "4                                  4                      4   \n",
       "\n",
       "   score_enjoyable_annoying  score_organized_cluttered  \\\n",
       "0                         2                          6   \n",
       "1                         1                          6   \n",
       "2                         3                          4   \n",
       "3                         1                          6   \n",
       "4                         4                          6   \n",
       "\n",
       "   score_addictive_non_addictive  score_supportive_obstructive  \\\n",
       "0                              4                             6   \n",
       "1                              3                             4   \n",
       "2                              7                             5   \n",
       "3                              4                             3   \n",
       "4                              4                             4   \n",
       "\n",
       "   score_pressuring_suggesting  score_boring_exciting  score_revealed_covert  \\\n",
       "0                            6                      4                      5   \n",
       "1                            5                      3                      3   \n",
       "2                            2                      6                      2   \n",
       "3                            4                      7                      2   \n",
       "4                            4                      1                      4   \n",
       "\n",
       "   score_complicated_easy  score_unpredictable_predictable  \\\n",
       "0                       5                                3   \n",
       "1                       6                                4   \n",
       "2                       6                                1   \n",
       "3                       5                                4   \n",
       "4                       3                                4   \n",
       "\n",
       "   score_friendly_unfriendly  score_deceptive_benevolent data_source  \n",
       "0                          3                           5       Human  \n",
       "1                          1                           4       Human  \n",
       "2                          3                           4       Human  \n",
       "3                          2                           3       Human  \n",
       "4                          2                           4       Human  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load human data\n",
    "human_data = pd.read_csv(\"Formatting Human Survey Data/raw_participant_evaluations.csv\")\n",
    "\n",
    "# Fix column name for consistency\n",
    "if 'score_addictive_non-addictive' in human_data.columns:\n",
    "    human_data = human_data.rename(columns={'score_addictive_non-addictive': 'score_addictive_non_addictive'})\n",
    "\n",
    "# Add data source column\n",
    "human_data['data_source'] = 'Human'\n",
    "\n",
    "print(f\"Human data shape: {human_data.shape}\")\n",
    "human_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File model_analysis_test/results_qwen-vl-max.csv has statistical headers, skipping first row\n",
      "Model data shape: (59, 44)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metadata_timestamp</th>\n",
       "      <th>metadata_ai_service</th>\n",
       "      <th>metadata_model</th>\n",
       "      <th>metadata_pattern_type</th>\n",
       "      <th>metadata_interface_id</th>\n",
       "      <th>score_inefficient_efficient</th>\n",
       "      <th>score_interesting_not_interesting</th>\n",
       "      <th>score_clear_confusing</th>\n",
       "      <th>score_enjoyable_annoying</th>\n",
       "      <th>score_organized_cluttered</th>\n",
       "      <th>...</th>\n",
       "      <th>6.1</th>\n",
       "      <th>7</th>\n",
       "      <th>3.2</th>\n",
       "      <th>2.1</th>\n",
       "      <th>4.1</th>\n",
       "      <th>5.1</th>\n",
       "      <th>6.2</th>\n",
       "      <th>6.3</th>\n",
       "      <th>The popup is perceived as inefficient and obstructive due to its repetitive nature. It is also seen as pressuring rather than suggesting, making it unfriendly and annoying. The feature is not particularly interesting or exciting, and it is somewhat confusing and complicated.</th>\n",
       "      <th>data_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-01T15:35:41.758887</td>\n",
       "      <td>anthropic</td>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>Nagging</td>\n",
       "      <td>interface_001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AI Model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-01T15:35:52.881322</td>\n",
       "      <td>anthropic</td>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>Overcomplicated Process</td>\n",
       "      <td>interface_002</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AI Model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-01T15:36:04.711931</td>\n",
       "      <td>anthropic</td>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>Hindering Account Deletion</td>\n",
       "      <td>interface_003</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AI Model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-01T15:36:16.000749</td>\n",
       "      <td>anthropic</td>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>Sneaking Bad Default</td>\n",
       "      <td>interface_004</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AI Model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-01T15:36:27.400215</td>\n",
       "      <td>anthropic</td>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>Expectation Result Mismatch</td>\n",
       "      <td>interface_005</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AI Model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           metadata_timestamp metadata_ai_service          metadata_model  \\\n",
       "0  2025-04-01T15:35:41.758887           anthropic  claude-3-opus-20240229   \n",
       "1  2025-04-01T15:35:52.881322           anthropic  claude-3-opus-20240229   \n",
       "2  2025-04-01T15:36:04.711931           anthropic  claude-3-opus-20240229   \n",
       "3  2025-04-01T15:36:16.000749           anthropic  claude-3-opus-20240229   \n",
       "4  2025-04-01T15:36:27.400215           anthropic  claude-3-opus-20240229   \n",
       "\n",
       "         metadata_pattern_type metadata_interface_id  \\\n",
       "0                      Nagging         interface_001   \n",
       "1      Overcomplicated Process         interface_002   \n",
       "2   Hindering Account Deletion         interface_003   \n",
       "3         Sneaking Bad Default         interface_004   \n",
       "4  Expectation Result Mismatch         interface_005   \n",
       "\n",
       "   score_inefficient_efficient  score_interesting_not_interesting  \\\n",
       "0                          2.0                                6.0   \n",
       "1                          2.0                                6.0   \n",
       "2                          2.0                                6.0   \n",
       "3                          7.0                                3.0   \n",
       "4                          2.0                                5.0   \n",
       "\n",
       "   score_clear_confusing  score_enjoyable_annoying  score_organized_cluttered  \\\n",
       "0                    2.0                       6.0                        3.0   \n",
       "1                    6.0                       6.0                        7.0   \n",
       "2                    2.0                       6.0                        2.0   \n",
       "3                    3.0                       3.0                        3.0   \n",
       "4                    6.0                       6.0                        3.0   \n",
       "\n",
       "   ...  6.1   7  3.2  2.1  4.1  5.1  6.2  6.3  \\\n",
       "0  ...  NaN NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1  ...  NaN NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2  ...  NaN NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3  ...  NaN NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4  ...  NaN NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "   The popup is perceived as inefficient and obstructive due to its repetitive nature. It is also seen as pressuring rather than suggesting, making it unfriendly and annoying. The feature is not particularly interesting or exciting, and it is somewhat confusing and complicated.  \\\n",
       "0                                                NaN                                                                                                                                                                                                                                     \n",
       "1                                                NaN                                                                                                                                                                                                                                     \n",
       "2                                                NaN                                                                                                                                                                                                                                     \n",
       "3                                                NaN                                                                                                                                                                                                                                     \n",
       "4                                                NaN                                                                                                                                                                                                                                     \n",
       "\n",
       "  data_source  \n",
       "0    AI Model  \n",
       "1    AI Model  \n",
       "2    AI Model  \n",
       "3    AI Model  \n",
       "4    AI Model  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model data (combining all model results)\n",
    "model_files = [\n",
    "    \"model_analysis_test/results_anthropic_opus_neutral_description.csv\",\n",
    "    \"model_analysis_test/results_ollama_gemma3.csv\",\n",
    "    \"model_analysis_test/results_openai_gpt4-vision-neutral.csv\",\n",
    "    \"model_analysis_test/results_qwen-vl-max.csv\"\n",
    "]\n",
    "\n",
    "model_data_list = []\n",
    "for file in model_files:\n",
    "    try:\n",
    "        # First try normal loading\n",
    "        df = pd.read_csv(file)\n",
    "        # Check if first row contains statistical headers\n",
    "        if any(col in str(df.iloc[0]).lower() for col in ['mean', 'std', 'min', 'max']):\n",
    "            print(f\"File {file} has statistical headers, skipping first row\")\n",
    "            df = pd.read_csv(file, skiprows=1)\n",
    "        model_data_list.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "# Combine all model data\n",
    "model_data = pd.concat(model_data_list, ignore_index=True)\n",
    "\n",
    "# Fix column name for consistency\n",
    "if 'score_addictive_non-addictive' in model_data.columns:\n",
    "    model_data = model_data.rename(columns={'score_addictive_non-addictive': 'score_addictive_non_addictive'})\n",
    "\n",
    "# Add data source column\n",
    "model_data['data_source'] = 'AI Model'\n",
    "\n",
    "print(f\"Model data shape: {model_data.shape}\")\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate UX KPI\n",
    "\n",
    "Calculate the UX KPI for both human and model assessments based on negative UX aspects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Data with UX KPI:\n",
      "         metadata_pattern_type  ux_kpi worst_aspect  worst_value\n",
      "0      Overcomplicated Process   4.250    cluttered            6\n",
      "1         Sneaking Bad Default   4.250    cluttered            6\n",
      "2          Toying With Emotion   4.875    confusing            7\n",
      "3                  Endlessness   3.375    cluttered            6\n",
      "4  Expectation Result Mismatch   4.750       boring            7\n",
      "\n",
      "Model Data with UX KPI:\n",
      "         metadata_pattern_type metadata_ai_service          metadata_model  \\\n",
      "0                      Nagging           anthropic  claude-3-opus-20240229   \n",
      "1      Overcomplicated Process           anthropic  claude-3-opus-20240229   \n",
      "2   Hindering Account Deletion           anthropic  claude-3-opus-20240229   \n",
      "3         Sneaking Bad Default           anthropic  claude-3-opus-20240229   \n",
      "4  Expectation Result Mismatch           anthropic  claude-3-opus-20240229   \n",
      "\n",
      "   ux_kpi     worst_aspect  worst_value  \n",
      "0   4.250      obstructive          7.0  \n",
      "1   6.000        cluttered          7.0  \n",
      "2   3.375  not_interesting          6.0  \n",
      "3   3.125    unpredictable          5.0  \n",
      "4   5.000           boring          6.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/66/73cb2jcd6jg68q_rlbh1rhzw0000gp/T/ipykernel_16749/3694105232.py:35: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  result_df['worst_aspect'] = result_df[ux_items].idxmax(axis=1).str.replace('ux_', '')\n"
     ]
    }
   ],
   "source": [
    "def calculate_ux_kpi(df):\n",
    "    \"\"\"Calculate UX KPI based on negative UX aspects.\"\"\"\n",
    "    # Create a copy to avoid modifying the input\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Define UX KPI components\n",
    "    ux_kpi_items = {\n",
    "        'boring': 'score_boring_exciting',           # Low = boring\n",
    "        'not_interesting': 'score_interesting_not_interesting',  # High = not interesting\n",
    "        'complicated': 'score_complicated_easy',     # Low = complicated\n",
    "        'confusing': 'score_clear_confusing',        # High = confusing\n",
    "        'inefficient': 'score_inefficient_efficient', # Low = inefficient\n",
    "        'cluttered': 'score_organized_cluttered',     # High = cluttered\n",
    "        'unpredictable': 'score_unpredictable_predictable', # Low = unpredictable\n",
    "        'obstructive': 'score_supportive_obstructive'  # High = obstructive\n",
    "    }\n",
    "    \n",
    "    # Create columns with standardized values (higher = worse UX)\n",
    "    for ux_item, column in ux_kpi_items.items():\n",
    "        if column in result_df.columns:\n",
    "            if ux_item in ['not_interesting', 'confusing', 'cluttered', 'obstructive']:\n",
    "                # These are already oriented so high values = negative aspect\n",
    "                result_df[f'ux_{ux_item}'] = result_df[column]\n",
    "            else:\n",
    "                # Invert these so high values = negative aspect\n",
    "                result_df[f'ux_{ux_item}'] = 8 - result_df[column]  # 8 - value (1-7 scale)\n",
    "    \n",
    "    # Calculate UX KPI (mean of all items)\n",
    "    ux_items = [f'ux_{item}' for item in ux_kpi_items.keys() if f'ux_{item}' in result_df.columns]\n",
    "    \n",
    "    if ux_items:\n",
    "        result_df['ux_kpi'] = result_df[ux_items].mean(axis=1)\n",
    "        \n",
    "        # Also determine worst aspect for each row\n",
    "        result_df['worst_aspect'] = result_df[ux_items].idxmax(axis=1).str.replace('ux_', '')\n",
    "        result_df['worst_value'] = result_df[ux_items].max(axis=1)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Calculate UX KPI for human data\n",
    "human_data_with_kpi = calculate_ux_kpi(human_data)\n",
    "\n",
    "# Calculate UX KPI for model data\n",
    "model_data_with_kpi = calculate_ux_kpi(model_data)\n",
    "\n",
    "# Show sample results\n",
    "print(\"Human Data with UX KPI:\")\n",
    "print(human_data_with_kpi[['metadata_pattern_type', 'ux_kpi', 'worst_aspect', 'worst_value']].head())\n",
    "\n",
    "print(\"\\nModel Data with UX KPI:\")\n",
    "print(model_data_with_kpi[['metadata_pattern_type', 'metadata_ai_service', 'metadata_model', 'ux_kpi', 'worst_aspect', 'worst_value']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Human and Model Assessments\n",
    "\n",
    "Now let's generate a comparison of the average UX KPI for each pattern type between humans and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "Not allowed to merge between different levels. (1 levels on the left, 2 on the right)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMergeError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      9\u001b[39m model_pivot = model_pattern_kpi.pivot_table(\n\u001b[32m     10\u001b[39m     index=\u001b[33m'\u001b[39m\u001b[33mmetadata_pattern_type\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     11\u001b[39m     columns=[\u001b[33m'\u001b[39m\u001b[33mmetadata_ai_service\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmetadata_model\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     12\u001b[39m     values=\u001b[33m'\u001b[39m\u001b[33mux_kpi\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     13\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Merge human and model data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m combined_kpi = \u001b[43mhuman_pattern_kpi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_pivot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmetadata_pattern_type\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mouter\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Sort by human UX KPI (worst to best)\u001b[39;00m\n\u001b[32m     19\u001b[39m combined_kpi = combined_kpi.sort_values(\u001b[33m'\u001b[39m\u001b[33mhuman_ux_kpi\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/AI-UI-Ethics-Evaluations/venv/lib/python3.12/site-packages/pandas/core/frame.py:10832\u001b[39m, in \u001b[36mDataFrame.merge\u001b[39m\u001b[34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m  10813\u001b[39m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m  10814\u001b[39m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents=\u001b[32m2\u001b[39m)\n\u001b[32m  10815\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmerge\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m  10828\u001b[39m     validate: MergeValidate | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  10829\u001b[39m ) -> DataFrame:\n\u001b[32m  10830\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmerge\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[32m> \u001b[39m\u001b[32m10832\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  10833\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m  10834\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10835\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10836\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10837\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10838\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10839\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10840\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10841\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10842\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10843\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10845\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10846\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/AI-UI-Ethics-Evaluations/venv/lib/python3.12/site-packages/pandas/core/reshape/merge.py:170\u001b[39m, in \u001b[36mmerge\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[32m    156\u001b[39m         left_df,\n\u001b[32m    157\u001b[39m         right_df,\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         copy=copy,\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     op = \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result(copy=copy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/AI-UI-Ethics-Evaluations/venv/lib/python3.12/site-packages/pandas/core/reshape/merge.py:784\u001b[39m, in \u001b[36m_MergeOperation.__init__\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    778\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _left.columns.nlevels != _right.columns.nlevels:\n\u001b[32m    779\u001b[39m     msg = (\n\u001b[32m    780\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNot allowed to merge between different levels. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    781\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_left.columns.nlevels\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m levels on the left, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    782\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_right.columns.nlevels\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m on the right)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    783\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(msg)\n\u001b[32m    786\u001b[39m \u001b[38;5;28mself\u001b[39m.left_on, \u001b[38;5;28mself\u001b[39m.right_on = \u001b[38;5;28mself\u001b[39m._validate_left_right_on(left_on, right_on)\n\u001b[32m    788\u001b[39m (\n\u001b[32m    789\u001b[39m     \u001b[38;5;28mself\u001b[39m.left_join_keys,\n\u001b[32m    790\u001b[39m     \u001b[38;5;28mself\u001b[39m.right_join_keys,\n\u001b[32m   (...)\u001b[39m\u001b[32m    793\u001b[39m     right_drop,\n\u001b[32m    794\u001b[39m ) = \u001b[38;5;28mself\u001b[39m._get_merge_keys()\n",
      "\u001b[31mMergeError\u001b[39m: Not allowed to merge between different levels. (1 levels on the left, 2 on the right)"
     ]
    }
   ],
   "source": [
    "# Calculate average UX KPI for each pattern type - Human data\n",
    "human_pattern_kpi = human_data_with_kpi.groupby('metadata_pattern_type')['ux_kpi'].mean().reset_index()\n",
    "human_pattern_kpi = human_pattern_kpi.rename(columns={'ux_kpi': 'human_ux_kpi'})\n",
    "\n",
    "# Calculate average UX KPI for each pattern type and model\n",
    "model_pattern_kpi = model_data_with_kpi.groupby(['metadata_pattern_type', 'metadata_ai_service', 'metadata_model'])['ux_kpi'].mean().reset_index()\n",
    "\n",
    "# Create a pivot table for model UX KPI\n",
    "model_pivot = model_pattern_kpi.pivot_table(\n",
    "    index='metadata_pattern_type',\n",
    "    columns=['metadata_ai_service', 'metadata_model'],\n",
    "    values='ux_kpi'\n",
    ")\n",
    "\n",
    "# Merge human and model data\n",
    "combined_kpi = human_pattern_kpi.merge(model_pivot, left_on='metadata_pattern_type', right_index=True, how='outer')\n",
    "\n",
    "# Sort by human UX KPI (worst to best)\n",
    "combined_kpi = combined_kpi.sort_values('human_ux_kpi', ascending=False)\n",
    "\n",
    "# Display comparison table\n",
    "print(\"UX KPI Comparison (Higher values = Worse UX):\")\n",
    "combined_kpi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Comparison\n",
    "\n",
    "Let's create a bar chart to compare human vs. model average UX KPI for each pattern type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for visualization\n",
    "# Melt the pivot table to get it in a format suitable for plotting\n",
    "plot_data = combined_kpi.melt(\n",
    "    id_vars=['metadata_pattern_type', 'human_ux_kpi'],\n",
    "    var_name=['ai_service', 'model'],\n",
    "    value_name='model_ux_kpi'\n",
    ")\n",
    "\n",
    "# Create a long-format dataframe for easier plotting\n",
    "comparison_data = []\n",
    "\n",
    "for idx, row in plot_data.iterrows():\n",
    "    pattern = row['metadata_pattern_type']\n",
    "    \n",
    "    # Add human data\n",
    "    comparison_data.append({\n",
    "        'pattern_type': pattern,\n",
    "        'source': 'Human',\n",
    "        'model': 'Human',\n",
    "        'ux_kpi': row['human_ux_kpi']\n",
    "    })\n",
    "    \n",
    "    # Add model data\n",
    "    if not pd.isna(row['model_ux_kpi']):\n",
    "        comparison_data.append({\n",
    "            'pattern_type': pattern,\n",
    "            'source': row['ai_service'],\n",
    "            'model': row['model'],\n",
    "            'ux_kpi': row['model_ux_kpi']\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "# Create bar chart\n",
    "plt.figure(figsize=(16, 10))\n",
    "ax = sns.barplot(x='pattern_type', y='ux_kpi', hue='source', data=comparison_df)\n",
    "\n",
    "# Customize chart\n",
    "plt.title('UX KPI Comparison: Human vs. AI Models', fontsize=16)\n",
    "plt.xlabel('Pattern Type', fontsize=14)\n",
    "plt.ylabel('UX KPI (Higher = Worse UX)', fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Source', fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "plt.savefig(os.path.join(output_dir, 'human_model_ux_kpi_comparison.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Gauge Visualizations\n",
    "\n",
    "Now let's create gauge visualizations for both human and model assessments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gauge visualizations for human assessments\n",
    "human_gauges_dir = os.path.join(output_dir, 'human_gauges')\n",
    "os.makedirs(human_gauges_dir, exist_ok=True)\n",
    "\n",
    "# Calculate average ux values, worst aspect, and UX KPI for each pattern type\n",
    "human_pattern_avg = human_data_with_kpi.groupby('metadata_pattern_type').agg({\n",
    "    'ux_kpi': 'mean',\n",
    "    'worst_aspect': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
    "    'worst_value': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Create gauge for each pattern type\n",
    "for _, row in human_pattern_avg.iterrows():\n",
    "    pattern = row['metadata_pattern_type']\n",
    "    worst_aspect = row['worst_aspect']\n",
    "    worst_value = row['worst_value']\n",
    "    ux_kpi = row['ux_kpi']\n",
    "    \n",
    "    # Determine color based on worst_value\n",
    "    if worst_value > 5:\n",
    "        text_color = \"lightcoral\"\n",
    "    elif worst_value > 3:\n",
    "        text_color = \"orange\"\n",
    "    else:\n",
    "        text_color = \"lightgreen\"\n",
    "    \n",
    "    # Create gauge visualization\n",
    "    fig = go.Figure(go.Indicator(\n",
    "        mode=\"gauge+number+delta\",\n",
    "        value=worst_value,\n",
    "        domain={'x': [0, 1], 'y': [0, 0.9]},\n",
    "        delta={\n",
    "            'reference': ux_kpi,\n",
    "            'font': {'size': 1},\n",
    "            'position': \"bottom\",\n",
    "            'relative': False,\n",
    "            'increasing': {'symbol': \" \"},\n",
    "            'decreasing': {'symbol': \" \", 'color': \"white\"},\n",
    "            'valueformat': \" \"\n",
    "        },\n",
    "        title={\n",
    "            'text': f\"<span style='font-size:1em;color:gray'>{pattern} (Human)</span><br>\" +\n",
    "                   f\"<span style='font-size:1em;color:black'>UX KPI: {ux_kpi:.2f}</span>\",\n",
    "            'font': {'size': 24}\n",
    "        },\n",
    "        number={\n",
    "            'font': {'size': 80, 'color': text_color},\n",
    "            'suffix': f\"<br><b><span style='font-size:1.0em;color:{text_color}'>{worst_aspect}</span>\",\n",
    "        },\n",
    "        gauge={\n",
    "            'axis': {'range': [1, 7]},\n",
    "            'bar': {'color': \"green\" if worst_value < 3 else \"orange\" if worst_value < 5 else \"red\"},\n",
    "            'steps': [\n",
    "                {'range': [1, 3], 'color': \"lightgreen\"},\n",
    "                {'range': [3, 5], 'color': \"lightyellow\"},\n",
    "                {'range': [5, 7], 'color': \"lightcoral\"}\n",
    "            ],\n",
    "            'threshold': {\n",
    "                'line': {'color': \"black\", 'width': 4},\n",
    "                'thickness': 0.75,\n",
    "                'value': ux_kpi\n",
    "            }\n",
    "        }\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        margin=dict(l=20, r=20, t=50, b=100),\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    # Save gauge visualization\n",
    "    file_path = os.path.join(human_gauges_dir, f\"{pattern.replace(' ', '_')}.png\")\n",
    "    fig.write_image(file_path)\n",
    "    \n",
    "    # Display a few gauges\n",
    "    if _ < 3:\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gauge visualizations for model assessments (one per model for each pattern)\n",
    "for service in model_data_with_kpi['metadata_ai_service'].unique():\n",
    "    for model in model_data_with_kpi[model_data_with_kpi['metadata_ai_service'] == service]['metadata_model'].unique():\n",
    "        # Create directory for this model\n",
    "        model_gauges_dir = os.path.join(output_dir, f\"{service}_{model}_gauges\")\n",
    "        os.makedirs(model_gauges_dir, exist_ok=True)\n",
    "        \n",
    "        # Filter data for this model\n",
    "        model_filter = (model_data_with_kpi['metadata_ai_service'] == service) & \\\n",
    "                       (model_data_with_kpi['metadata_model'] == model)\n",
    "        this_model_data = model_data_with_kpi[model_filter]\n",
    "        \n",
    "        # Calculate average ux values, worst aspect, and UX KPI for each pattern type\n",
    "        model_pattern_avg = this_model_data.groupby('metadata_pattern_type').agg({\n",
    "            'ux_kpi': 'mean',\n",
    "            'worst_aspect': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
    "            'worst_value': 'mean'\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Create gauge for each pattern type\n",
    "        for _, row in model_pattern_avg.iterrows():\n",
    "            pattern = row['metadata_pattern_type']\n",
    "            worst_aspect = row['worst_aspect']\n",
    "            worst_value = row['worst_value']\n",
    "            ux_kpi = row['ux_kpi']\n",
    "            \n",
    "            # Skip if any values are NaN\n",
    "            if pd.isna(pattern) or pd.isna(worst_aspect) or pd.isna(worst_value) or pd.isna(ux_kpi):\n",
    "                continue\n",
    "            \n",
    "            # Determine color based on worst_value\n",
    "            if worst_value > 5:\n",
    "                text_color = \"lightcoral\"\n",
    "            elif worst_value > 3:\n",
    "                text_color = \"orange\"\n",
    "            else:\n",
    "                text_color = \"lightgreen\"\n",
    "            \n",
    "            # Create gauge visualization\n",
    "            fig = go.Figure(go.Indicator(\n",
    "                mode=\"gauge+number+delta\",\n",
    "                value=worst_value,\n",
    "                domain={'x': [0, 1], 'y': [0, 0.9]},\n",
    "                delta={\n",
    "                    'reference': ux_kpi,\n",
    "                    'font': {'size': 1},\n",
    "                    'position': \"bottom\",\n",
    "                    'relative': False,\n",
    "                    'increasing': {'symbol': \" \"},\n",
    "                    'decreasing': {'symbol': \" \", 'color': \"white\"},\n",
    "                    'valueformat': \" \"\n",
    "                },\n",
    "                title={\n",
    "                    'text': f\"<span style='font-size:1em;color:gray'>{pattern} ({service} {model})</span><br>\" +\n",
    "                           f\"<span style='font-size:1em;color:black'>UX KPI: {ux_kpi:.2f}</span>\",\n",
    "                    'font': {'size': 24}\n",
    "                },\n",
    "                number={\n",
    "                    'font': {'size': 80, 'color': text_color},\n",
    "                    'suffix': f\"<br><b><span style='font-size:1.0em;color:{text_color}'>{worst_aspect}</span>\",\n",
    "                },\n",
    "                gauge={\n",
    "                    'axis': {'range': [1, 7]},\n",
    "                    'bar': {'color': \"green\" if worst_value < 3 else \"orange\" if worst_value < 5 else \"red\"},\n",
    "                    'steps': [\n",
    "                        {'range': [1, 3], 'color': \"lightgreen\"},\n",
    "                        {'range': [3, 5], 'color': \"lightyellow\"},\n",
    "                        {'range': [5, 7], 'color': \"lightcoral\"}\n",
    "                    ],\n",
    "                    'threshold': {\n",
    "                        'line': {'color': \"black\", 'width': 4},\n",
    "                        'thickness': 0.75,\n",
    "                        'value': ux_kpi\n",
    "                    }\n",
    "                }\n",
    "            ))\n",
    "            \n",
    "            fig.update_layout(\n",
    "                margin=dict(l=20, r=20, t=50, b=100),\n",
    "                height=600\n",
    "            )\n",
    "            \n",
    "            # Save gauge visualization\n",
    "            file_path = os.path.join(model_gauges_dir, f\"{pattern.replace(' ', '_')}.png\")\n",
    "            fig.write_image(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Worst Aspects\n",
    "\n",
    "Compare which aspects were rated as worst by humans vs. models for each pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparison table of worst aspects\n",
    "worst_aspect_comparison = human_pattern_avg[['metadata_pattern_type', 'worst_aspect']].rename(\n",
    "    columns={'worst_aspect': 'human_worst_aspect'}\n",
    ")\n",
    "\n",
    "# Add model worst aspects\n",
    "for service in model_data_with_kpi['metadata_ai_service'].unique():\n",
    "    for model in model_data_with_kpi[model_data_with_kpi['metadata_ai_service'] == service]['metadata_model'].unique():\n",
    "        model_filter = (model_data_with_kpi['metadata_ai_service'] == service) & \\\n",
    "                       (model_data_with_kpi['metadata_model'] == model)\n",
    "        this_model_data = model_data_with_kpi[model_filter]\n",
    "        \n",
    "        # Calculate most common worst aspect for each pattern type\n",
    "        model_worst_aspects = this_model_data.groupby('metadata_pattern_type')['worst_aspect'].agg(\n",
    "            lambda x: x.mode()[0] if not x.mode().empty else None\n",
    "        ).reset_index()\n",
    "        \n",
    "        model_worst_aspects = model_worst_aspects.rename(\n",
    "            columns={'worst_aspect': f'{service}_{model}_worst_aspect'}\n",
    "        )\n",
    "        \n",
    "        # Add to comparison table\n",
    "        worst_aspect_comparison = worst_aspect_comparison.merge(\n",
    "            model_worst_aspects, on='metadata_pattern_type', how='outer'\n",
    "        )\n",
    "\n",
    "# Display comparison table\n",
    "print(\"Comparison of Worst UX Aspects:\")\n",
    "worst_aspect_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Agreement Between Humans and Models\n",
    "\n",
    "Calculate how closely models' assessments align with human assessments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation between human and model UX KPI scores\n",
    "correlation_results = []\n",
    "\n",
    "for service in model_data_with_kpi['metadata_ai_service'].unique():\n",
    "    for model in model_data_with_kpi[model_data_with_kpi['metadata_ai_service'] == service]['metadata_model'].unique():\n",
    "        # Get model UX KPI for each pattern\n",
    "        model_filter = (model_data_with_kpi['metadata_ai_service'] == service) & \\\n",
    "                       (model_data_with_kpi['metadata_model'] == model)\n",
    "        \n",
    "        model_kpi = model_data_with_kpi[model_filter].groupby('metadata_pattern_type')['ux_kpi'].mean()\n",
    "        \n",
    "        # Merge with human data\n",
    "        merged_data = pd.DataFrame({\n",
    "            'human_ux_kpi': human_data_with_kpi.groupby('metadata_pattern_type')['ux_kpi'].mean()\n",
    "        })\n",
    "        merged_data[f'{service}_{model}_ux_kpi'] = model_kpi\n",
    "        \n",
    "        # Calculate correlation\n",
    "        try:\n",
    "            corr = merged_data['human_ux_kpi'].corr(merged_data[f'{service}_{model}_ux_kpi'])\n",
    "            \n",
    "            # Calculate mean absolute error\n",
    "            mae = abs(merged_data['human_ux_kpi'] - merged_data[f'{service}_{model}_ux_kpi']).mean()\n",
    "            \n",
    "            # Calculate agreement on worst aspect\n",
    "            human_worst = human_pattern_avg.set_index('metadata_pattern_type')['worst_aspect']\n",
    "            \n",
    "            model_worst = this_model_data.groupby('metadata_pattern_type')['worst_aspect'].agg(\n",
    "                lambda x: x.mode()[0] if not x.mode().empty else None\n",
    "            )\n",
    "            \n",
    "            # Count matching worst aspects\n",
    "            combined = pd.DataFrame({\n",
    "                'human': human_worst,\n",
    "                'model': model_worst\n",
    "            })\n",
    "            \n",
    "            matching = (combined['human'] == combined['model']).sum()\n",
    "            total = len(combined.dropna())\n",
    "            \n",
    "            aspect_agreement = matching / total if total > 0 else 0\n",
    "            \n",
    "            correlation_results.append({\n",
    "                'service': service,\n",
    "                'model': model,\n",
    "                'correlation': corr,\n",
    "                'mean_abs_error': mae,\n",
    "                'worst_aspect_agreement': aspect_agreement,\n",
    "                'worst_aspect_matching': f\"{matching}/{total}\"\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating correlation for {service} {model}: {e}\")\n",
    "\n",
    "# Create dataframe and sort by correlation\n",
    "correlation_df = pd.DataFrame(correlation_results).sort_values('correlation', ascending=False)\n",
    "\n",
    "# Display results\n",
    "print(\"Human-Model Agreement:\")\n",
    "correlation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Summary Table of UX KPI By Pattern\n",
    "\n",
    "Create a clean, easy-to-read table of UX KPI scores for each pattern, comparing humans and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clean summary table\n",
    "summary_table = pd.DataFrame({\n",
    "    'Pattern Type': human_pattern_avg['metadata_pattern_type'],\n",
    "    'Human UX KPI': human_pattern_avg['ux_kpi'],\n",
    "    'Human Worst Aspect': human_pattern_avg['worst_aspect']\n",
    "})\n",
    "\n",
    "# Add model data\n",
    "for service in model_data_with_kpi['metadata_ai_service'].unique():\n",
    "    for model in model_data_with_kpi[model_data_with_kpi['metadata_ai_service'] == service]['metadata_model'].unique():\n",
    "        if pd.isna(model):\n",
    "            continue\n",
    "            \n",
    "        model_filter = (model_data_with_kpi['metadata_ai_service'] == service) & \\\n",
    "                      (model_data_with_kpi['metadata_model'] == model)\n",
    "        this_model_data = model_data_with_kpi[model_filter]\n",
    "        \n",
    "        model_pattern_avg = this_model_data.groupby('metadata_pattern_type').agg({\n",
    "            'ux_kpi': 'mean',\n",
    "            'worst_aspect': lambda x: x.mode()[0] if not x.mode().empty else None\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Skip if empty\n",
    "        if len(model_pattern_avg) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Create a temporary dataframe\n",
    "        temp_df = pd.DataFrame({\n",
    "            'Pattern Type': model_pattern_avg['metadata_pattern_type'],\n",
    "            f'{service} {model} UX KPI': model_pattern_avg['ux_kpi'],\n",
    "            f'{service} {model} Worst Aspect': model_pattern_avg['worst_aspect']\n",
    "        })\n",
    "        \n",
    "        # Merge with summary table\n",
    "        summary_table = summary_table.merge(temp_df, on='Pattern Type', how='outer')\n",
    "\n",
    "# Sort by Human UX KPI (worst to best)\n",
    "summary_table = summary_table.sort_values('Human UX KPI', ascending=False)\n",
    "\n",
    "# Display summary table\n",
    "print(\"UX KPI Summary by Pattern Type:\")\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary table to CSV\n",
    "summary_table.to_csv(os.path.join(output_dir, 'ux_kpi_summary.csv'), index=False)\n",
    "print(f\"Summary saved to {os.path.join(output_dir, 'ux_kpi_summary.csv')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has provided:\n",
    "1. A clear comparison of UX KPI metrics between human and model assessments\n",
    "2. Gauge visualizations for each pattern type showing worst aspects\n",
    "3. Analysis of agreement between humans and different AI models\n",
    "4. Summary tables that can be easily referenced for presentations or papers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
